[["index.html", "『Rによる原因を推論する』 久米ゼミにようこそ！", " 『Rによる原因を推論する』 北川 梨津，原 健人 2022-06-03 21:18:53 久米ゼミにようこそ！ 久米郁男ゼミにようこそ．これから皆さんは，因果推論の方法を2年間みっちり学びます．久米ゼミでは，因果推論のツールとして主に計量分析を利用します．計量分析のためには，数多くの統計解析を行ってくれる統計ソフトウェアを使いこなせることが不可欠です．本書は，『原因を推論する』で提示されるフレームワークに添いながら，Rというプログラミング言語による初歩的な計量分析を実践的に解説することを目的とします． 2年間，因果推論と計量分析をまじめに学べば，あなたの市場価値は飛躍的に高まるはずです．その第一歩を確実に踏み出しましょう．努力は実らないこともありますが，実るまで努力すれば1の確率で実ります．ともに原因を推論する旅に出ましょう！ "],["introintro.html", "はじめる前に おことわり 著者について", " はじめる前に おことわり 本書は，プレゼミに参加している2年生を読者として想定しています．計量分析について彼らが何も知らないと仮定した上で，短い期間で「回帰分析についてなんとなく理解して計量分析の論文がなんとか読める」ようにすることおよび「自分自身でもなんちゃって重回帰分析ができる」ようにすることを本書は目的としています．厳密な理解よりも，直感的な(ふわっとした？)わかりやすさを最優先したため，いくつかの説明は曖昧であったり，厳密でなかったりします．また，著者の知識も決して十分ではないため，それによる誤りも少なからず存在しているものと思われます．その点を理解した上で，本書をご利用なさるようにお願いします．なお，ゼミの学生により執筆されており，久米郁男教授は本書の内容についてなんら関与していません．本書の誤りはすべて著者の学生に帰するものです． 本書はまだ執筆中のため頻繁に更新されますので，ご注意ください．また，明らかな誤りや明らかに不適切な記述などがありましたら，Twitter: @ritsu1997までお知らせください． 追加コメント：本書のデータはすべてシミュレーションで作成した架空のものです.したがって，その分析結果自体には意味がありませんので，ご注意ください．やや非現実的なデータになっていますが，いずれもう少し現実的な架空データをシミュレーションでつくるか現実のデータを使うようにするかして，改善します．とりあえず，今期(2019年)のプレゼミに間に合うように作りました． 著者について 北川梨津 これの著者1．Twitter: @ritsu1997．特に何も受賞していないが，いつか受賞できるように頑張っている．早稲田大学政治経済学部経済学科．2019年4月に早稲田大学大学院経済学研究科進学予定． 原健人 これの著者2．政治計量テキスト分析に明るい．学部の卒業論文「熟議は誰の影響を受けるか」で2019年度政治経済学会論文コンクール最優秀賞受賞．その論文を国際シンポジウム「熟議民主主義の実践と実験」で発表した．早稲田大学政治経済学部国際政治経済学科．2019年4月に早稲田大学大学院経済学研究科進学予定． "],["intro.html", "チャプター1 はじめに 1.1 R言語とは 1.2 RStudioとは 1.3 基本操作", " チャプター1 はじめに 1.1 R言語とは R言語とは統計解析に特化したプログラミング言語です．Rには大きなコミュニティーが存在し，多くの教科書やオンラインのリソースがあるだけでなく，新しいパッケージが日進月歩開発されています．意外と汎用性もあるので，非常に魅力的な統計プログラミング言語です． R以外にもStataやSPSSなどの統計ソフトウェアがあります．しかし，StataやSPSSは有料で非常に高額です．大学に在籍している間は使えますが，卒業してから企業で使うのは少し難しいです．対して，Rは無料です．なので，長く安心して使うことができます． たまに，PythonとR，どちらを使えばいいですかという質問が来ます．その答えは両方です．Pythonの方が汎用性は圧倒的にありますし，とりわけ機械学習などに興味がある場合はPythonの方が便利でしょう．しかし，Pythonで計量分析を行うとなると，Rに比べてコーディングが冗長になるきらいがあります．なので，データを扱う仕事に興味があるのなら，両方を学ぶようにすることが無難です． 1.2 RStudioとは RStudioとはRのための統合開発環境(IDE)です．IDEとは簡単に言えば，コードを書きやすくするための道具です．単に「R」と言うときは，RStudioを指していることが多いです． 1.3 基本操作 1.3.1 四則演算 簡単な計算から始めましょう．コードが書けたら，Windowsの場合はCtrl + Enter，Macの場合はCommand + Returnを入力することで実行(Run)することができます． 1 + 1 # 足し算 ## [1] 2 5 - 10 # 引き算 ## [1] -5 9 * 9 # 掛け算 ## [1] 81 2 / 3 # 割り算 ## [1] 0.6666667 2 ^ 4 # 累乗 ## [1] 16 sqrt(9) # 平方根 ## [1] 3 1.3.2 文字列 ダブルクォーテーションマークを使って，文字列を扱うことができます． &quot;Hello, World!&quot; ## [1] &quot;Hello, World!&quot; &quot;We love Ikuo&quot; ## [1] &quot;We love Ikuo&quot; &quot;久米ゼミ&quot; ## [1] &quot;久米ゼミ&quot; 1.3.3 割り当て演算 &lt;-という割り当て演算子を用いることで，値をオブジェクトとして任意の名前に格納することができます． a &lt;- 5 a ## [1] 5 b &lt;- 4 + 6 b ## [1] 10 a + b ## [1] 15 kume &lt;- &quot;LOVE&quot; kume ## [1] &quot;LOVE&quot; 1.3.4 ベクトル c()関数を用いて，ベクトルをつくることができます．cとはcombineのcです．ベクトルとは値の連なりです．Rでは基本的にデータをベクトルとして扱います．ベクトルに含まれる値を要素(element)と呼びます． vector &lt;- c(1, 2, 3) vector ## [1] 1 2 3 tutors &lt;- c(&quot;Kitagawa&quot;, &quot;Saito&quot;, &quot;Ryuman&quot;, &quot;Takahashi&quot;) tutors ## [1] &quot;Kitagawa&quot; &quot;Saito&quot; &quot;Ryuman&quot; &quot;Takahashi&quot; ベクトルに含まれる要素の個数を長さ(length)と呼びます．例えば，c(1, 2, 3)というベクトルには3つの要素が含まれているので，このベクトルの長さは3です．ベクトルに含まれる要素の個数が大きくなってくると，ベクトルの長さを数えるのが大変です．length()関数を用いれば，ベクトルの長さを簡単に確認できます． v &lt;- c(1, 2, 3) length(v) ## [1] 3 あるオブジェクトがベクトルかどうかをis.vector()関数を使って確認できます．次のコードを試してみましょう． a &lt;- c(1) is.vector(a) ## [1] TRUE b &lt;- 1 is.vector(b) ## [1] TRUE どちらもTRUEと出力されますね．実は，c(1)と1は同じベクトルです．長さ1のベクトルをスカラーと呼ぶことにします． 1.3.5 ベクトルの演算 ベクトルとベクトルの演算を確認します．基本的に，順番が同じ要素の組について 計算して，その値を要素とする新たなベクトルが出力されます． x &lt;- c(10, 10, 10) y &lt;- c(1, 2, 3) x + y # 足し算 ## [1] 11 12 13 x - y # 引き算 ## [1] 9 8 7 x * y # 掛け算 ## [1] 10 20 30 x / y # 割り算 ## [1] 10.000000 5.000000 3.333333 y ^ 2 # 累乗 ## [1] 1 4 9 sqrt(y) # 平方根 ## [1] 1.000000 1.414214 1.732051 x %*% y # 内積 ## [,1] ## [1,] 60 ベクトルとスカラーの演算を確認します．ベクトルとスカラーの演算では，スカラーがベクトルの長さ分だけ繰り返されます．実際に試してみましょう． x &lt;- c(1, 2, 3, 4, 5) x - 3 ## [1] -2 -1 0 1 2 1.3.5.1 関数 関数を用いることで，さまざまな演算を行うことができます．平方根を求める際に用いたsqrt()も関数の一つです．一般に，関数はf(x)の形をしています．関数の中に入れる値xを引数(argument)と呼びます．指定された引数にしたがって，関数は値を出力します．その出力される値のことを戻り値(return value)と呼びます．関数の例をいくつか見てみましょう． sqrt(100) # 引数の平方根を出力 ## [1] 10 round(5.555) # 丸め ## [1] 6 date() # 日時 ## [1] &quot;Fri Jun 3 21:18:55 2022&quot; 自分で関数を定義することもできます． bmi &lt;- function(weight, height){ index &lt;- weight / height^2 return(index) } bmi(70, 1.7) ## [1] 24.22145 1.3.6 csvファイルの読み込み データセットのファイル形式はcsvであることが多いです．csvファイルはread.csv関数で読み込むことができます．さらに，file.choose()によって読み込むファイルをGUIで指定することができます．架空のデータセットwage.csvを読み込みましょう．wage.csvはここからダウンロードできます． mydata &lt;- read.csv(file.choose()) データフレームが格納された名前を実行すると，そのデータフレームの中身を確認できます．しかし，データフレームの名前を実行すると，データフレームの中身が全て出力されるので見づらいです．head()関数を用いれば，データフレームのはじめ数行だけを表示することができます．また，View()関数を用いると，表形式でデータフレームの中身を確認することもできます． mydata head(mydata) View(mydata) 1.3.7 サブセッティング Rでは，データセットをデータフレームとして扱います．データフレームの列(column)には名前が付いています．その列名を変数名と呼ぶこともあります．列名を見るにはcolnames()関数が便利です． colnames(mydata) ## [1] &quot;X&quot; &quot;salary&quot; &quot;educ&quot; &quot;abili&quot; &quot;iq&quot; &quot;female&quot; &quot;age&quot; &quot;exper&quot; データフレームの中から，ある変数(列)だけを取り出したい場合があります．その際には，$というサブセッティング演算子を用います．salaryという変数だけを取り出してみましょう． mydata$salary "],["summarization.html", "チャプター2 データを要約する 2.1 平均値 2.2 分散 2.3 標準偏差 2.4 ヒストグラム 2.5 散布図 2.6 相関係数", " チャプター2 データを要約する 本章では，平均値や分散，相関係数などの基本的な統計学を復習します． 2.1 平均値 平均値を求めるにはmean()関数を用います．mean()関数の引数はベクトルでなくてはなりません． mean(mydata) # mydataはベクトルではなく，データフレームなのでエラーになります 次のように平均値を求めたい変数をサブセッティングして，ベクトルにする必要があります． mean(mydata$salary) ## [1] 883.1841 mean(mydata$educ) ## [1] 13.026 2.2 分散 分散を求めるにはvar()関数を用います．分散はデータのばらつきを把握するための統計量です1． var(mydata$salary) ## [1] 111308.5 var(mydata$educ) ## [1] 7.482807 2.3 標準偏差 分散は単位が2乗になっているので少しわかりづらいです．なので，分散の平方根をとって単位の次数を減らしたものが標準偏差です．標準偏差を求めるにはsd()関数を用います． sd(mydata$salary) ## [1] 333.6292 2.4 ヒストグラム 図によってデータの分布を確認するには，ヒストグラムを用いるのが便利です．ヒストグラムを作図するにはhist()関数を用います． hist(mydata$salary) hist()関数には複数の引数があり，それらを指定することで見た目を変えることができます． hist(mydata$salary, col = &quot;lightblue&quot;, main = &quot;Histogram of Salary&quot;, xlab = &quot;Salary&quot;) 2.5 散布図 2つの変数の関係を図で確認するためには，散布図を用いるのが便利です．散布図を作成するにはplot()関数を使います．今わたしたちは，教育と年収の関係性に関心があるとしましょう．educと年収salaryの関係を次のように図示できます． plot(mydata$educ, mydata$salary, main = &quot;Salary and Education&quot;, xlab = &quot;Years of Education&quot;, ylab = &quot;Salary&quot;) Exercise 2.1 次のことを考えてみてください． どのような関係が見て取れますか？ そのような関係はどのようなメカニズム生じるのでしょうか？ それは因果関係と言えるでしょうか？ 3で，そのように答えた理由は何ですか？ 2.6 相関係数 相関係数は，2つの変数の直線的な関係の強さを表します．相関係数\\(\\rho\\)は，\\(-1 \\leq \\rho \\leq1\\)の値を取ります．2つの変数の直線的な関係は，0に近いほど弱く，絶対値が1に近いほど強いです．相関係数が正のとき(\\(\\rho&gt;0\\))，散布図は右上がりの分布を描きます．相関係数が負のとき(\\(\\rho&lt;0\\))，散布図は右下がりの分布を描きます． Rではcor()関数を用いることで，相関係数を求めることができます．educとsalaryの相関係数は0.577です． cor(mydata$educ, mydata$salary) ## [1] 0.5771089 Exercise 2.2 wage.csvのデータについて，次の指示に従ってください． 年齢(age)の平均，分散，標準偏差を求めてください．また，ageのヒストグラムを作成してください． 年齢(age)と年収(salary)の散布図を描いて，さらに相関係数を求めてください． 2の結果について考察しなさい． 厳密にはvar()関数は不偏分散です．↩︎ "],["regression.html", "チャプター3 回帰分析 3.1 回帰分析とは 3.2 単回帰分析 3.3 最小二乗法 3.4 重回帰分析 3.5 回帰分析と因果推論", " チャプター3 回帰分析 本章では，因果推論をするために有用なツールとなる回帰分析を学びます2． 3.1 回帰分析とは 回帰分析(regression analysis)とは，大雑把に言うと，2つ以上の変数の関係を方程式で表すことです．例えば，中学数学で習った \\(y=ax+b\\) というような一次方程式をイメージしてください．これは \\(x\\) という変数が0のとき，変数 \\(y\\) は \\(b\\) という値を取り， \\(x\\) が1増えるごとに \\(y\\) が \\(a\\) 増えるという関係を表しています． 回帰分析とは，ある変数と変数の関係性が\\(y=ax+b\\)というような方程式で表現できる仮定して，その係数\\(a\\)や切片\\(b\\)を手元のデータから推定することを言います．特に，そのような関係式のことを回帰式と呼びます．回帰式のことを統計的モデルまたは単にモデルということもあります． このとき，左辺にある変数を被説明変数(explained variable)と呼びます．基本的に，回帰式に従属変数は1つだけ含まれます．対して，右辺にある変数を説明変数(explanatory variable)と呼びます．説明変数は1つ以上回帰式に含めることができます． 3.2 単回帰分析 単回帰分析(simple linear regression)とは，回帰式に説明変数が1つだけ含まれる回帰分析のことを指します．慣習的に，回帰式は次の通りに書かれることが多いです． \\[ y = \\beta_0 + \\beta_1x + \\varepsilon \\] \\(y\\)が被説明変数，\\(\\beta_0\\)が定数項(切片)，\\(\\beta_1\\)が説明変数\\(x\\)の係数です．回帰式の係数のことを特に回帰係数と呼びます． さて，新しく追加された\\(\\varepsilon\\)とは何でしょうか．これは誤差項と呼ばれるもので，確率的に生じる誤差を表しています．社会科学において観察される変数と変数の関係は，\\(y = \\beta_0 + \\beta_1x\\)というような方程式で完全に表現できることはあまりありません． 例えば，わたしたちは今，教育年数(educ)と年収(salary)の関係に興味があるとしましょう．回帰分析の結果，どうやら\\(salary=300+30educ\\)であるとわかったとします3．このことは，教育年数が2年の人はみんながみんな年収360万円であるということを意味するでしょうか？そんなことは直感的にもありえませんね．教育年数が同じ人の間でも，何らかの誤差が生じていて年収は多かれ少なかれ異なると考えるのが自然です．その誤差を捉えるのが\\(\\varepsilon\\)です． では，教育年数が同じ人の間でも何らかの誤差が生じていて年収が異なるのであれば，\\(salary=300+30educ\\)は無意味な数式なのでしょうか．それは違います．その式が表しているのは，「教育と年収には，平均的にこの関係があるようだ」ということです．大雑把に言うと，教育年数が2年の人はみんながみんな年収360万円ではないけれど平均的にはそのくらいだ，ということになります．これが回帰分析の基本的なアイディアです．このアイディア自体は重回帰分析でも共通です． 3.3 最小二乗法 ある変数とある変数の関係を，理論的な考察によって，\\(y=\\beta_0+\\beta_1x+\\varepsilon\\)という回帰式でモデル化できそうだということがわかっているとしましょう．しかし，このときどのようにして\\(\\beta_0\\)や\\(\\beta_1\\)の値を知ることができるでしょうか．結論を言うと，\\(\\beta_0\\)や\\(\\beta_1\\)の本当の値を知ることは決してできません．なぜなら，わたしたちが観察できるのは，\\(y=\\beta_0+\\beta_1x+\\varepsilon\\)というモデルに従って発生した具体的なデータ\\((y_i, x_i)\\)だけだからです． \\(\\beta_0\\)や\\(\\beta_1\\)の本当の値を知ることはできませんが，手元にある具体的なデータ\\((y_i, x_i)\\)から，\\(\\beta_0\\)や\\(\\beta_1\\)の値を推測することは可能です．\\(\\beta_0\\)や\\(\\beta_1\\)の値を推測することを推定(estimation)と言います．なお，推定するための計算式(関数)を推定量(estimator)と呼びます．その計算式によって算出された実際の値を推定値(esitmate)と呼びます． 次の具体的なデータを例に考えてみましょう．今，わたしたちは学生の1ヶ月あたりの書籍購入費とGPAの関係に興味があるとします．このとき，入手したデータが次の散布図を描きました．どのような関係が見て取れるでしょうか？4 右上がりの関係が見て取れますね． さて，わたしたちは，\\(y=\\beta_0+\\beta_1x+\\varepsilon\\)という回帰式を仮定している訳ですが，それはつまり，「観測されるデータは\\(y=\\beta_0+\\beta_1x\\)という直線の関係に平均的に従うはずだ」と考えているということです． ひるがえって，「観測されたデータがいかにも従っていそうな直線」を描くことができれば，\\(\\beta_0\\)や\\(\\beta_1\\)の値を推定することができそうですね．では，「観測されたデータがいかにも従っていそうな直線」とはどのような直線でしょうか？ ものは試しです．いくつか直線を引いてみました．以下の4つの中で，どれが最も「観測されたデータがいかにも従っていそうな直線」だと思いますか？ これは一目瞭然，簡単ですね．2番目が最も「観測されたデータがいかにも従っていそうな直線」だと誰しもが答えると思います．なぜなら，この中で最もいい感じにフィットしているからです． それでは次の場合はどうでしょうか？どれが最も「いい感じにフィットしている」でしょうか？ 微妙なところですが，多くの人はなんとなく4番が最も「いい感じにフィットしている」と答えるのではないでしょうか？しかし，何人かは「わからないやあ」と答えるかもしれません．もし，あなたも4番が最も「いい感じにフィットしている」と感じたのであれば，そのような優柔不断な人々にどのように説明しますか？ 優柔不断な人々を説得するためには，「いい感じにフィットしている」というやや曖昧な表現をもう少し明確な言葉で言い換える必要があるでしょう．「いい感じにフィットしている」というのは，どのような言葉で明確に言い換えられるでしょうか．少し考えてみましょう． 「いい感じにフィットしている」というのは，「直線がどの点に対してもなるべく近い」ということを意味していると思います．その基準にのっとれば，4番が最も「いい感じにフィットしている」と説得的に説明できるのではないでしょうか．「直線がどの点に対してもなるべく近い」というのを\\(\\beta_0\\)や\\(\\beta_1\\)の値を推定するときの基準として採用しましょう． 「直線がどの点に対してもなるべく近い」という基準にのっとって，\\(\\beta_0\\)や\\(\\beta_1\\)の推定値を計算する方法を最小二乗法(ordinary least squares)と呼びます．「直線がどの点に対してもなるべく近い」という基準をもう少し数学的に厳密に定義して直線を求める方法です．すなわち，次のように定義される\\(\\widehat{\\beta}_0\\)と\\(\\widehat{\\beta}_1\\)を，\\(\\beta_0\\)や\\(\\beta_1\\)の値を推定する関数として採用する方法です． \\[ \\begin{eqnarray} \\DeclareMathOperator*{\\argmin}{argmin} (\\widehat{\\beta}_0,\\widehat{\\beta}_1) &amp;=&amp; \\argmin_{\\beta_0,\\beta_1} \\ \\sum_{i=1}^n \\ \\{ \\ y_i-\\beta_0-\\beta_1x_i \\ \\}^2 \\end{eqnarray} \\] これを手計算で求めるのはあまり楽ではありません．どれほど計算が得意な人でも，かなりの時間がかかってしまいます．そんなときこそ，Rの出番です．Rでは簡単なコードを書くだけで，\\(\\beta_0\\)や\\(\\beta_1\\)を最小二乗法によって推定することができます． 最小二乗法による回帰を行うためには，lm()関数を用います．lm()関数には，主に2つの引数があります．dataとformulaです． dataには用いるデータフレームを指定します．formulaには回帰式を指定します．回帰式を表現するには~(チルダ，tilde)を用います．左には被説明変数を書き，右には説明変数を書きます．例えば，\\((x_i, y_i)\\)に対して\\(y=\\beta_0+\\beta_1x+\\varepsilon\\)というモデルを仮定している場合，y ~ xのようにして回帰式を指定します． lm()関数を割り当て演算子によって，オブジェクトとして名前に格納しておくと，最小二乗法による推定結果のさまざまな情報がその名前に記録されます．olsを実行すると，定数項と係数の推定値が出力されます． ols &lt;- lm(formula = salary ~ educ, data = mydata) ols ## ## Call: ## lm(formula = salary ~ educ, data = mydata) ## ## Coefficients: ## (Intercept) educ ## -33.67 70.39 このデータの場合，\\(\\beta_0\\)は-33.67，\\(\\beta_1\\)は70.39と推定されていることがわかります．この場合，教育年数が1年増えると，年収が平均的に70万円増える(傾向がある)と解釈するのでしたね．定数項については解釈をすることはあまりありません． plot()関数によって散布図を描いた後に，abline()関数を用いて，推定された回帰直線を描くことができます．データに対して「いい感じにフィットしている」ことを確認してください． plot(mydata$educ, mydata$salary) abline(ols) 3.4 重回帰分析 重回帰分析(simple linear regression)とは，単回帰分析を拡張した分析方法で，回帰式に説明変数が2つ以上含まれる回帰分析のことを指します．回帰式は次の通りに書かれます．ここでは，説明変数が2つの場合を考えましょう．説明変数は\\(x_1\\)と\\(x_2\\)の2つです． \\[ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\varepsilon \\] 説明変数が増えたこと以外は，単回帰分析とアイデアは同じで，最小二乗法によりモデルを推定することができます．説明変数が2つの場合には，3次元空間上の散布図に「いい感じにフィットする平面」を描くことに対応します．が，あまり難しいことは考えずに，単回帰分析の強化版だと思ってください．「3次元空間上の散布図にいい感じにフィットする平面」というのは，以下の図のようなイメージです． 最小二乗法による重回帰分析もRで簡単に行えます．単回帰分析の場合と同様に，lm()関数を用います．+を使って回帰式を指定することで説明変数を2つ以上入れることができます．ここではsalaryをeducとiqに回帰してみましょう． multiple &lt;- lm(salary ~ educ + iq, data = mydata) multiple ## ## Call: ## lm(formula = salary ~ educ + iq, data = mydata) ## ## Coefficients: ## (Intercept) educ iq ## -1677.01 16.17 23.53 単回帰分析のときと同様に，定数項や係数の推定値が求められました．重回帰分析の場合は，少しだけ解釈の仕方が変わります．重回帰分析の場合は， 「教育年数が1年増えると，他の変数(この場合iq)が変化しないならば，年収が16.17万円増える」と解釈します．この「他の変数が変化しないならば」という但し書きが重要です．「他の変数が変化しない」という条件のことを，セテリスパリブス(ceteris paribus)と言います．また，iqに関しても，iqが1単位増えると，セテリスパリブスで，年収が16.172増えるとも解釈できます． 3.5 回帰分析と因果推論 さて，繰り返しになってしまいますが，単回帰分析と重回帰分析の違いは説明変数が1つしかないのか2つ以上あるのかどうかだけです．それでは重回帰分析をすると何が嬉しいのでしょうか？単回帰分析をそれぞれの説明変数について行うのと何が違うのでしょうか？ それを考えるためには，因果関係の3条件を思い出しましょう． 説明変数と被説明変数の間に共変関係がある．(共変関係) 説明変数の変化は被説明変数の変化の前に生じている．(時間的先行) 他の変数を統制(コントロール)しても(他の変数の値を固定しても)共変関係が観察される．(他の変数の統制) 以上3つでしたね(久米 2013, p.15)． 回帰分析によって達成できるのは，因果関係の3条件のうち，1と3です．本章では簡単のため，2の時間的先行は満たされていると仮定しましょう．共変関係とは，ある値が変化すると，別のある値も変化するような関係を言いました．共変関係があるかどうかは散布図や相関係数によって確かめれば十分であることも多いですが，単回帰分析によって調べることもできます．単回帰式を推定して，説明変数の回帰係数の推定値が0でなければ共変関係があると言えるでしょう． しかし，社会科学の分野では，それだけでは因果関係があると言うのに不十分であることが通常です．因果関係の3条件の 3番目である「他の変数の統制」が満たされないことが多いからです．つまり，第三の変数が存在しているかもしれないということです．ここで言う第三の変数とは，説明変数にも被説明変数にも影響を与えている変数のことを指します． 例えば，教育と所得の関係を考えてみましょう．教育が所得に与える影響を見たいとします．このときに考えられる第三の変数として，“能力”が挙げられます．そもそも能力が高いから，良い教育を受けているのであって，そもそも能力が高いから良い所得を有しているということが考えられます． もし教育と能力が相関していれば，良い教育を受ける人は能力が高い傾向にあることになります．そして，もし能力と年収が相関していれば，能力が高い人は所得が高い傾向にあるということになりますね．すなわち，教育は所得に直接的に与える影響と，能力を経由して間接的に与えている(ように見える)影響とを持っていると考えることができます． このとき，所得と教育の単回帰分析を行うとどうなるでしょうか．結論を言うと，教育の回帰係数の推定値は，教育の直接的な影響だけでなく，能力の影響まで含んでしまいます．それでは，教育の本当の効果を推測することができません．第三の変数が存在しているとき，その推定はバイアスがかかっています．今回の例に即すれば，推定値は上方にバイアスがかかっていることが想定されるでしょう． このようなときに重回帰分析が役に立つのです．重回帰分析では2つ以上の説明変数をモデルに組み入れることができました．それによって，セテリスパリブス(他の変数が変化しないという条件)における効果を推定することができるのでしたね．もしも，能力という変数が観測できるのであれば，それをモデルに組み込むことでその影響を捉えて，教育の効果から分離することができます．このように，関心のある説明変数(ここでは教育！)を正確に推定するために他の変数をモデルに組み入れることを，他の変数を統制(control)すると言います．統制される変数は統制変数と呼ばれます． このように，重回帰分析の利点は他の変数を統制することで，関心のある説明変数の効果を正しく推定することができるのです．すなわち，重回帰分析とは，因果関係の3つの条件の3番目を満たすための有力なツールなのです． 実際に回帰分析をしてみましょう．mydataには年収salaryと教育年数educに加えて，能力abiliという変数があります．いま，わたしたちは教育年数が年収に与える影響に関心があるとします．まずは，単回帰分析をしてみましょう． simple &lt;- lm(formula = salary ~ educ, data = mydata) simple ## ## Call: ## lm(formula = salary ~ educ, data = mydata) ## ## Coefficients: ## (Intercept) educ ## -33.67 70.39 教育年数が1年増えると，年収が70.39万円増えるということがわかります．しかし，先ほども話した通り，能力という第三の変数が推定にバイアスをかけている可能性があります．そこで，abiliを統制変数として追加して重回帰分析をしてみましょう． multiple &lt;- lm(salary ~ educ + abili, data = mydata) multiple ## ## Call: ## lm(formula = salary ~ educ + abili, data = mydata) ## ## Coefficients: ## (Intercept) educ abili ## 692.59 14.85 24.16 能力について統制すると，educの係数が55.54ほど小さくなりましたね．やはり，単回帰分析では，能力を経由した間接的な効果を，教育の効果であるとバイアスのかかった推定をしていたようです． 以上のように，因果関係の3条件の3番目「他の変数の統制」を，重回帰分析を用いることで満足することができるのです．ただし，重回帰分析が第三の変数の問題を解決できるのは，その第三の変数を観察できるとき，すなわちそのデータが入手できるときに限ります．例えば，本来，能力というような抽象的な変数は観察できません． そこでしなくてはならないのが，操作化(operationalization)です5．すなわち，他の観察可能な変数によって観察不可能な変数を代替するということです．そのような変数を代理変数(proxy variable)と呼びます． 例えば，能力を知識であると捉えて，それをIQなどの指標で代替できるかもしれません．IQを能力の代理変数として用いるわけです．mydataにはiqという変数があります．ここでは，abiliが観察されなかったと仮定して，iqを代理変数として用いてみましょう． ols &lt;- lm(formula = salary ~ educ + iq, data = mydata) ols ## ## Call: ## lm(formula = salary ~ educ + iq, data = mydata) ## ## Coefficients: ## (Intercept) educ iq ## -1677.01 16.17 23.53 salary ~ educ + abiliの結果からは少しだけずれますが，これは代理変数が測定の誤差を含んでいることに起因する分析の誤差であると考えられます．とはいえ，ほとんど変わらないので，今回の場合は代理変数がある程度しっかりと代理していると言えそうです． 代理変数を用いるときには，それが正しく本来の変数を代理しているかどうかを検討することが大事です．理想的には，代理変数と本来の変数が強く相関していることが望ましいです．しかし，本来の変数はそもそも観察不可能なわけですから理論や直観に基づいて検討する他ありません．代理変数を用いる際には，気をつけましょう． Exercise 3.1 次の問いに答えましょう． 単回帰分析と重回帰分析の違いは何ですか？ 単回帰分析の限界は何ですか？ 最小二乗法とは何ですか？わかりやすく説明してください． 本書では，回帰分析と言う場合，線形回帰分析を意味しています↩︎ これは架空の回帰分析です．↩︎ 実際には，このデータは打ち切りデータなので，Tobitを用いることが適切ですが，簡単のためここでは打ち切りによるバイアスは生じないものと仮定しましょう．↩︎ 計量経済学における操作変数法(instrumental variable method)とは異なります．↩︎ "],["test.html", "チャプター4 統計的仮説検定 4.1 誤差で”ゴサ”います？ 4.2 す桃じゃないよ，p値だよ 4.3 有意，“ある”意味ね？ 4.4 始めようか天体観測 4.5 ほうき星を探して", " チャプター4 統計的仮説検定 本章では統計的仮説検定について簡単に説明します． 4.1 誤差で”ゴサ”います？ 前章では回帰分析のやり方を学びました．lm()関数を用いることで，回帰係数を推定することができました．説明変数が被説明変数に対して効果を持つとき，その回帰係数は0ではないはずです．なので，回帰係数は0ではないときに効果があると結論するわけでした． しかし，実際の分析においては必ず誤差がありますので，たとえ効果が全くないとしても，その回帰係数の推定値がぴったり0となることはあまりありません．したがって，「推定値が単なる誤差とは思えないほどに0から十分に離れている」ときに効果があると結論することになります． それでは，推定値がどれくらい0から離れていれば，0から十分に離れている，すなわち効果があると言えるのでしょうか．すなわち，どのようなときに推定値の値に意味がある，有意(significant)であると言うことができるでしょうか． 例えば，lm(data = mydata, salary ~ educ + iq)を実行すると，educの回帰係数の推定値は16.17となります．それは，教育年数が1年増えると年収が約16万円増えると解釈するのでした．これなら0から十分に離れている値であるとなんとなく言えそうですね． では，もしも回帰係数の推定値が0.1だったらどうでしょうか？それだと誤差の範囲内な気がしますね．では，推定値が0.5だったらどうでしょう．それでも誤差の範囲内？1だったらどうですか？2は？3は？ 回帰係数の推定値が微妙なラインにあるときには，人によって誤差の範囲内だと感じるかもしれませんし，誤差であるとは思えないと感じるかもしれません．ある値が(絶対値で)0よりも十分に大きいかどうかというのは主観的な判断になってしまいます． このように，どれくらいの値なら0から十分に離れていると言えるのかというのは人によって異なります．そのため，回帰係数の推定値が0から十分に離れている，有意である，と言うためには，人の主観によらない何らかの客観的な基準が必要になりそうです． 4.2 す桃じゃないよ，p値だよ 回帰係数の推定値が単なる誤差とは思えないほどに0から十分に離れているかどうかの基準として，p値が使われます．回帰係数の 推定値について，p値という指標を手元のデータから計算することができます．その具体的な計算の仕方は本書のレベルを超えるので，参考文献にあたってください． p値は，「もしも本当の回帰係数が0であるときに，いま手元のデータから計算された推定値以上の推定値がたまたま誤差によって生じる確率」を意味しています．すなわち，「本当の回帰係数が0であって，推定値は誤差によってたまたま0から離れてしまっているだけに過ぎないと仮定すると，いま手元のデータから計算された推定値がどれほど極端な値なのか」を表す指標です．なお，このような「回帰係数が0である」すなわち「効果がない」という仮定のことを帰無仮説と言います p値をさらに簡単に言うと，「帰無仮説が正しいとしたときに，この推定値が誤差の範囲であるかどうか」の指標です．p値が大きい時には推定値が単なる誤差によるものである可能性が高いという意味になります．ひるがえって，p値が小さいときには推定値が単なる誤差によるものである可能性が低いという意味になります． さて，p値をつかってどのように「回帰係数の推定値が単なる誤差とは思えないほどに0から十分に離れている」と結論するのでしょうか．その論証の仕方は背理法(proof by contradiction)に少し似ています． 背理法とは，「Aである」と証明するために，まず，「Aでない」と仮定するのでした．そして，その仮定から導かれる矛盾を示すことで，「Aでない，ではない」すなわち「Aである」と主張するのでした． p値を使って「回帰係数の推定値が単なる誤差ではなく意味がある」と結論する際の手続きは背理法に似ています．まず，「回帰係数の本当の値は0だ」と仮定します．背理法のように，この仮定から矛盾的な事実を示せれば，「回帰係数の本当の値は0ではない」と結論することができるはずです．その矛盾的な事実を示すのに使われるのがp値です． p値がとても小さいとき，それは手元のデータから計算された推定値が誤差によってたまたま得られる確率はとても低いということを意味します．すなわち，とても稀なことが起きているということです．「こんなに稀なことが起きるなんて，不思議すぎる…これは，仮定が間違っていると考えないと無理がある」と考えて，帰無仮説を誤りであるとして退けるのです．このような論証の手続きを統計的仮説検定と言います． p値がとても小さいことを根拠に，帰無仮説を誤りであるとして退けることを，「帰無仮説を棄却する」と言います．帰無仮説が棄却されると，帰無仮説の否定にあたる「回帰係数の本当の値は0ではない」が正しいとして結論するのです．なお，帰無仮説の否定にあたる仮説を対立仮説と呼びます．このようにして，回帰係数の推定値が0から十分に離れているのかどうか，意味を持っているのかどうかを客観的に判断することができるのです． 4.3 有意，“ある”意味ね？ さて，実際のところp値がどれほど小さければ，とても小さいと言えるでしょうか．その基準は学問領域の慣習によって決められていることが多いです．それを下回ればとても小さいと判断する閾値のことを，有意水準(level of significance)と言います．社会科学の場合は，5%の水準に設定されることが多いです．すなわち，p値が0.05より小さければ，とても小さい，したがって「回帰係数の本当の値は0ではない」と結論することを約束するわけです(p値は確率なので，0以上1以下の値をとることに注意してください)． 統計的仮説検定によって，帰無仮説が棄却されたとき，その推定値は「統計学的に有意である(statistically significant)」と言います．しかし，やや発展的ですが注意してほしいのは，帰無仮説が棄却されるということは，あくまで「“統計学的に”有意である」ということです．サンプルサイズすなわちデータ数を増やすとp値は必ず小さくなります．それは，どれほど回帰係数が0に近くても，サンプルサイズを十分に増やせば必ず統計学的に有意な結果が得られるということです． とはいえ，例えば，「年収(万円) = 定数項 + 教育年数(年) + 統制変数」という回帰式を推定したところ，教育年数の係数の推定値が0.5で，サンプルサイズがとても大きいために統計学的に有意であったとしましょう．統計学的に有意ではありますが，そのような小さな回帰係数に意味はあるでしょうか．この場合，20年の教育を受けてやっとこさ1万円の年収増になるわけですが，そのようなあまりに小さな効果に実際的な意味があると言えるでしょうか． 上記のような教育の効果を推定する回帰分析の目的は多くの場合，教育政策への応用です．たとえ，統計学的に有意な結果であったとしても，あまりに 効果が小さいのであれば実際的な意味があるとは言いづらいですね．このような推定値の実際的な意味のことを実際的有意性(practical significance)，または，経済学的有意性(economic significance)と言います．統計学的有意性だけではなく，実際的有意性にも注意するように心がけましょう． 4.4 始めようか天体観測 回帰分析の統計的仮説検定もRで簡単に行えます．summary()関数を用いることで，回帰分析の統計的仮説検定だけでなく，回帰分析の他のさまざまな結果を簡単に確認することができます． result &lt;- lm(formula = salary ~ educ + age + exper + iq, data = mydata) summary(result) ## ## Call: ## lm(formula = salary ~ educ + age + exper + iq, data = mydata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -662.24 -140.32 3.41 140.56 597.49 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1803.2587 79.7411 -22.614 &lt; 2e-16 *** ## educ 15.9920 3.1117 5.139 3.32e-07 *** ## age 4.1635 1.3228 3.147 0.0017 ** ## exper 0.0194 0.5605 0.035 0.9724 ## iq 23.5673 0.8664 27.203 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 206.3 on 995 degrees of freedom ## Multiple R-squared: 0.6192, Adjusted R-squared: 0.6177 ## F-statistic: 404.4 on 4 and 995 DF, p-value: &lt; 2.2e-16 さて，Estimateの列にそれぞれの回帰係数の推定値が表示されています．そして，Pr(&gt;|t|)という列に p値が表示されています．educのp値は2e-16ですが，これは指数表記というもので，\\(2\\times10^{-16}=\\frac{2}{10^{16}}\\)という値を表しています．とても小さな値で，0.05を下回ります．すなわち，educの係数の推定値は統計学的に有意であるということになります．統計学的に有意なものにはアルタリスク*という記号が付けられています．他にも統計学的に有意な推定値がありますね．一つだけ統計学的に有意でない推定値がありますね．それはexperで，p値は0.97で0.05を上回っていますね．このようにRを使って簡単に統計的仮説検定を行うことができます． 4.5 ほうき星を探して stargazer()という関数を使って，回帰分析の結果をきれいにまとめることができます．次のコードを実行してください． install.packages(&quot;stargazer&quot;) library(stargazer) stargazer(result, type = &quot;text&quot;) Dependent variable: salary educ 15.992*** (3.112) age 4.164*** (1.323) exper 0.019 (0.561) iq 23.567*** (0.866) Constant -1,803.259*** (79.741) Observations 1,000 R2 0.619 Adjusted R2 0.618 Residual Std. Error 206.298 (df = 995) F Statistic 404.447*** (df = 4; 995) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 複数の回帰分析の結果を比べやすく表示することもできます． model1 &lt;- lm(salary ~ educ, data = mydata) model2 &lt;- lm(salary ~ educ + age, data = mydata) model2 &lt;- lm(salary ~ educ + age + exper, data = mydata) model2 &lt;- lm(salary ~ educ + age + exper + iq, data = mydata) stargazer(model1, model2, model3, model4, type = &quot;text&quot;) Dependent variable: salary (1) (2) (3) (4) educ 70.387*** 70.313*** 70.294*** 15.992*** (3.153) (3.148) (3.150) (3.112) age 3.624** 3.620** 4.164*** (1.745) (1.746) (1.323) exper 0.172 0.019 (0.740) (0.561) iq 23.567*** (0.866) Constant -33.671 -140.780** -143.861** -1,803.259*** (41.965) (66.441) (67.782) (79.741) Observations 1,000 1,000 1,000 1,000 R2 0.333 0.336 0.336 0.619 Adjusted R2 0.332 0.335 0.334 0.618 Residual Std. Error 272.600 (df = 998) 272.149 (df = 997) 272.278 (df = 996) 206.298 (df = 995) F Statistic 498.375*** (df = 1; 998) 252.172*** (df = 2; 997) 167.973*** (df = 3; 996) 404.447*** (df = 4; 995) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 "],["regtech.html", "チャプター5 回帰分析のテクニック (準備中) 5.1 ダミー変数 5.2 交差項 5.3 多項式回帰 5.4 対数変換 5.5 パネルデータ", " チャプター5 回帰分析のテクニック (準備中) 本章は未完成です 本章では，回帰分析の際に有用なテクニックを紹介します． 5.1 ダミー変数 5.1.1 ダミー変数ってなんだ？ ダミー変数(Dummy Variable)とは，ある特定の条件を満たす場合は1，その条件を満たさない場合は0をとる変数です．二値変数とも呼ばれます 早速具体例を見てみましょう． \\[ female_i = \\begin{cases} 1 &amp; \\mbox{if } i\\mbox{ is a female} \\\\ 0 &amp; \\mbox{if } i\\mbox{ is not a female} \\end{cases} \\] 変数\\(female\\)は，「個人\\(i\\)がもし女性であれば1，女性でないならば0」をとるダミー変数です 6． 5.1.2 ダミー変数を用いた分析 実際にダミー変数を用いた重回帰分析を行ってみましょう．いま，「性別によって賃金(\\(salary\\))が異なる」という仮説を検証したいとしましょう． 仮説の検証のためにチャプター3で用いたモデルに\\(female\\)というダミー変数を追加して回帰分析を行います．モデル式は以下のように書くことができます． \\[ salary \\ = \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4iq + {\\beta}_5female + {\\varepsilon} \\] この式で\\(female\\)は1か0のいずれかの値をとります．ここである個人が女性でない場合(\\(female = 0\\))を考えてみましょう．モデル式に\\(female = 0\\)を代入するのでその項は消えてしまいますね． \\[ \\begin{align} \\ salary \\ &amp;= \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4iq + {\\beta}_5{\\times}0 + {\\varepsilon}\\\\ &amp;= \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4iq + {\\varepsilon} \\end{align} \\] では逆にある個人が女性である場合(\\(female = 1\\))を考えてみましょう．モデル式に\\(female = 0\\)を代入してみます． \\[ \\begin{align} \\ salary \\ &amp;= \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4iq + {\\beta}_5{\\times}1 + {\\varepsilon}\\\\ &amp;= \\ ({\\beta}_0 + {\\beta}_5) + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4iq + {\\varepsilon} \\end{align} \\] \\(female\\)の係数である\\({\\beta}_5\\)はそのまま残り，定数項\\({\\beta}_0\\)と足し合わせて新たな定数項\\(({\\beta}_0+{\\beta}_5)\\)を作り出しています．すなわち，\\(female\\)の係数は女性である場合とそうでない場合の切片の差であると解釈ができます． これを実際に分析してみましょう．コードは以下の通りに書くことができましたね． mydata &lt;- read.csv(&quot;wage2.csv&quot;) result &lt;- lm(formula = salary ~ educ + age + exper + iq + female, data = mydata) summary(result) Call: lm(formula = salary ~ educ + age + exper + iq + female, data = mydata) Residuals: Min 1Q Median 3Q Max -657.18 -142.67 4.35 141.53 602.75 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -1.797e+03 8.006e+01 -22.447 &lt; 2e-16 *** educ 1.598e+01 3.112e+00 5.134 3.41e-07 *** age 4.175e+00 1.323e+00 3.155 0.00165 ** exper 1.901e-02 5.606e-01 0.034 0.97295 iq 2.357e+01 8.665e-01 27.198 &lt; 2e-16 *** female -1.136e+01 1.310e+01 -0.867 0.38597 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 206.3 on 994 degrees of freedom Multiple R-squared: 0.6195, Adjusted R-squared: 0.6176 F-statistic: 323.6 on 5 and 994 DF, p-value: &lt; 2.2e-16 結果を見ると，femaleは5%水準で統計的有意性を示してはいません．すなわち，「他の変数を一定としたときに，女性であることは賃金salaryに影響を与えているとは言えない」という結論を得ることができます． 5.1.3 ダミー変数を用いるメリットとデメリット ダミー変数を用いることにはどのようなメリットがあるでしょうか．一方で，安易にダミー変数を使うことによる問題は起こらないのでしょうか． メリットの方からまとめておきます．メリットとしては係数の解釈や，そこから得られるインプリケーションが明確であることが挙げられるでしょう．「既婚者であれば1, と独身者であれば0」をとるようなダミー変数として表して分析を行った場合，その結果におけるダミー変数の係数は「独身の人が結婚した場合に得られる影響そのもの」です．ダミー変数は0か1で対象を二つに分割するため，0と1の差だけ考えればよいという意味で解釈は容易でしょう． 一方，安易にダミー変数を使ってしまうと問題が起こる可能性もあります．例えば「その国が民主主義体制なら1，権威主義体制なら0」というダミー変数を作って分析を行ったとします．確かにこの変数を使えば体制による従属変数への影響は明らかになるでしょう．しかしながら，一言に民主主義体制/権威主義体制と言ってもその中には様々な程度があります．ダミー変数ではこれらの差異までは表すことはできません．この代わりにFreedom House7の7点評価や，Polity IV Project8の10点評価の民主主義指数(Polity指数)で分析を行うことができれば，民主主義体制の国がさらに民主的になった場合や，権威主義体制の国がさらに権威主義を強めた場合の影響もとらえることができます．このようにダミー変数は，本来であれば測定できる影響を捨象してしまう可能性も含んでいる，「情報量の少ない変数」ということもできるでしょう． 5.2 交差項 5.2.1 交差させると見えてくる これまで重回帰分析を学び，ダミー変数まで扱えるようになりました．新たに交差項（interaction term）という分析のツールを習得しましょう． 交差項とは，変数同士を掛け合わせた変数のことをいいます．実際に交差項を入れたモデルの式を見てみましょう． \\[ salary \\ = \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4female + {\\beta}_5(educ{\\times}female)+ {\\varepsilon} \\] この\\((educ*female)\\)の項を交差項と呼びます．この項は何を表し，係数はどのように解釈をすればよいのでしょうか．交差項のタイプ別にみていくこととします． 交差項は非常に強力なツールです．使いこなせて損はありませんが，その係数をどう解釈すればよいのかが時に複雑に思えるときがありますので，モデル式から「係数が何を表すのか」を確認しておきましょう． 5.2.2 ダミー変数 × 量的変数 ダミー変数と連続変数の交差項を考えてみます．例えば以下の交差項はダミー変数×連続変数の交差項です． \\[ salary \\ = \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4female + {\\beta}_5(educ{\\times}female)+ {\\varepsilon} \\] \\(female\\)はこれまでの通り「女性であれば1, 女性でなければ0」という値をとるダミー変数です．一方で\\(educ\\)はその人の受けた教育年数を表す量的変数です．この変数はどのような意味を持ち，係数はどのように解釈をすることができるでしょうか．\\(female\\)が1をとる場合と\\(female\\)が0をとる場合でモデルがどのように変化をするか見てみましょう． まずは\\(female\\)が1をとる場合は以下のように計算できますね． \\[ \\begin{align} \\ salary \\ &amp;= \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4{\\times}1 + {\\beta}_5(educ{\\times}1) + {\\varepsilon}\\\\ &amp;= \\ ({\\beta}_0 + {\\beta}_4) + ({\\beta}_1 + {\\beta}_5)educ + {\\beta}_2age + {\\beta}_3exper + {\\varepsilon} \\end{align} \\] \\({\\beta}_5\\)は前節で見た通り，定数項とまとめることができます．そして\\({\\beta}_6\\)は\\(educ\\)でくくることができ，\\(educ\\)の新たな係数として\\(({\\beta}_1 + {\\beta}_6)\\)が現れます．交差項の係数\\({\\beta}_6\\)は，女性である場合\\((female = 1)\\)と女性でない場合\\((female = 0)\\)の変数\\(educ\\)の従属変数に与える影響の違いである，と考えることができます． もしこの交差項の係数が有意に正の値をとるとすれば，「教育年数が一年増加することによる賃金への影響は男性より女性の方が大きい」ということになります．逆にこの係数が負の値をとるとすれば，「女性の場合は教育年数が一年増加しても，男性ほどは賃金が上がらない」と解釈することができます． それでは具体的にこのモデルで分析をしてみましょう． lm1 &lt;- lm(formula = salary ~ educ + age + exper + female + educ*female, data = mydata) summary(lm1) Call: lm(formula = salary ~ educ + age + exper + female + educ * female, data = mydata) Residuals: Min 1Q Median 3Q Max -874.0 -191.2 9.8 186.7 998.5 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -62.5879 80.5933 -0.777 0.4376 educ 64.3475 4.6150 13.943 &lt;2e-16 *** age 3.7109 1.7450 2.127 0.0337 * exper 0.1709 0.7392 0.231 0.8172 female -156.2004 84.0250 -1.859 0.0633 . educ:female 11.0907 6.3109 1.757 0.0792 . --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 272.1 on 994 degrees of freedom Multiple R-squared: 0.3383, Adjusted R-squared: 0.335 F-statistic: 101.6 on 5 and 994 DF, p-value: &lt; 2.2e-16 結果を見ると，10%の有意水準でしか差があることを言えないので，社会科学においては統計的に有意ではないと結論付けることになります．しかし，一応傾向としてだけでもいえることを言っておくと，femaleの変数は有意に負の結果が出ています．これは，女性であることは賃金に負の影響を与えるという結果です． そして今回の関心であるeduc:femaleの交差項を観察すると，正に有意である傾向を見て取る頃ができます(10%)．これは，「女性が教育年数を1年増加させたときに起こる賃金の上昇は，男性より大きい」というように解釈ができます． より詳しく見てみます．数式に実際に推定された値を入れて，\\(female\\)が1の場合と0の場合を考えましょう． \\[ \\begin{align} \\ salary \\ &amp;= \\ -62.588 + 64.348educ + 3.711age + 0.171exper -156.200female + 11.091(educ{\\times}female) + {\\varepsilon}\\\\ &amp;= \\ (-62.588 -156.200) + (64.348 + 11.091)educ + 3.711age + 0.171exper + {\\varepsilon} \\ \\ \\ (if \\ female =1)\\\\ &amp;= \\ -62.588 + 64.348educ + 3.711age + 0.171exper + {\\varepsilon} \\ \\ \\ (if \\ female =0) \\end{align} \\] それぞれの差が定数項とeducの係数の差となって表れていますね．男性の場合教育年数を1年増加させたときにおこる賃金の上昇は64.348ですが，女性の場合は64.348 + 11.091 = 75.439の上昇があると推定されているということです． グラフで見るとよりわかりやすくなるでしょう． # in preparation 5.2.3 ダミー変数 × ダミー変数 次はダミー変数同士を掛け合わせたモデルを考えてみましょう．以下のモデルは\\(female\\)というダミー変数と\\(married\\)(既婚であれば1, 独身であれば0)をとるダミー変数を掛け合わせた交差項をモデルに組み込んでみましょう．モデルは以下の通りに書くことができます． \\[ salary \\ = \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4female + {\\beta}_5married + {\\beta}_6(female{\\times}married) + {\\varepsilon}\\\\ \\] この二つのダミー変数がどのように変化するかを考えてみましょう．世の中には「女性の既婚者」「女性の独身者」「男性の既婚者」「男性の独身者」の4つのタイプが存在しますね．それぞれでダミー変数がどのような値をとるか考えてみましょう． まず，ためしに「男性の独身者」を考えてみます．男性なので\\(female\\)は0です．そして独身者なので\\(married\\)も0をとります．これらを代入するとモデル式は以下の通りになります． \\[ \\begin{align} \\\\ salary \\ &amp;= \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4{\\times}0 + {\\beta}_5{\\times}0 + {\\beta}_6(0{\\times}0) + {\\varepsilon}\\\\ &amp;= \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\varepsilon} \\end{align} \\] 次に「女性の既婚者」を考えます．女性なので\\(female\\)は1をとり，既婚者なので\\(married\\)も1です．このときモデルは以下のように書くことができます． \\[ \\begin{align} \\\\ salary \\ &amp;= \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4{\\times}1 + {\\beta}_5{\\times}1 + {\\beta}_6(1{\\times}1) + {\\varepsilon}\\\\ &amp;= \\ ({\\beta}_0 + {\\beta}_4 +{\\beta}_5 +{\\beta}_6) + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\varepsilon} \\end{align} \\] すなわち「男性の独身者」と「女性の既婚者」の賃金は，\\(({\\beta}_4 + {\\beta}_5 + {\\beta}_6)\\)の値だけ異なると言えるでしょう． このようにダミー変数×ダミー変数の交差項はその係数の解釈が少々複雑です．以下にそれぞれのタイプの効果をまとめておきます． グループ 固有の係数 独身男性\\((female = 0, \\ married = 0)\\) \\({\\beta}_0\\) 既婚男性\\((female = 0, \\ married = 1)\\) \\({\\beta}_0 + {\\beta}_5\\) 独身女性\\((female = 1, \\ married = 0)\\) \\({\\beta}_0 + {\\beta}_4\\) 既婚女性\\((female = 1, \\ married = 1)\\) \\({\\beta}_0 + {\\beta}_4 + {\\beta}_5 + {\\beta}_6\\) では実際に分析を行ってみましょう． lm2 &lt;- lm(formula = salary ~ educ + age + exper + female + married + female*married, data = mydata) summary(lm2) Call: lm(formula = salary ~ educ + age + exper + female + married + female * married, data = mydata) Residuals: Min 1Q Median 3Q Max -820.1 -180.9 1.4 184.1 953.1 Coefficients: Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -164.8013 68.4481 -2.408 0.0162 * educ 67.0685 3.1499 21.292 &lt; 2e-16 *** age 3.2031 1.7209 1.861 0.0630 . exper 0.3694 0.7291 0.507 0.6125 female 10.5043 28.1859 0.373 0.7095 married 121.5582 26.4371 4.598 4.82e-06 *** female:married -33.1835 35.3870 -0.938 0.3486 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Residual standard error: 268 on 993 degrees of freedom Multiple R-squared: 0.3584, Adjusted R-squared: 0.3545 F-statistic: 92.44 on 6 and 993 DF, p-value: &lt; 2.2e-16 結果より，marriedは統計学的な有意性を示しますが，femaleと交差項female:marriedは統計的有意性を示していません．この結果はどのように解釈ができるでしょうか？ まずmarriedは正に有意なので，既婚者は独身者より賃金が高いという結論を得ることはできます．その一方で，femaleは有意ではないため，性別による賃金の差はないと考えられます．以上から「既婚状態は賃金に正に有意であるが，性別は賃金に有意な差を与えない」と結論できます． 5.2.4 量的変数 × 量的変数 これまでダミー変数を用いた交差項について書いてきましたが，ダミー変数ではないもので交差項を作ることも可能です．例えば以下のようなモデルです． \\[ salary \\ = \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + {\\beta}_3exper + {\\beta}_4female + {\\beta}_5(educ{\\times}exper)+ {\\varepsilon} \\] このモデルにおける項\\((educ*exper)\\)は「量的変数×量的変数」の交差項です．この項をモデルに入れることでどんなことがわかるでしょうか． 仮に今回は「仕事における経験年数(\\(exper\\))が賃金に与える影響」を知りたいとします．上記のモデルは\\(exper\\)でくくると以下のように書くことができますね． \\[ salary \\ = \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2age + ({\\beta}_3 + {\\beta}_5educ)exper + {\\beta}_4female + {\\varepsilon} \\] \\(exper\\)という変数の係数は\\(({\\beta}_3 + {\\beta}_5*educ)\\)です．すなわち，経験年数が1年増えると\\(({\\beta}_3 + {\\beta}_5*educ)\\)の賃金が増えることになります．この中に\\(educ\\)という変数が入っていますね．例えば\\({\\beta}_5\\)が正であるとしましょう．すると，\\(({\\beta}_3 + {\\beta}_5*educ)\\)という係数は，\\(educ\\)が大きくなればなるほど，大きなものになるとわかりますね．つまり，「教育年数が長いほど，経験年数の増加が賃金に与える影響は大きなものになる」と解釈ができるわけです．例えば具体的には，「高卒の人が1年経験年数が増加させたときの賃金への影響より，大卒の人が1年経験年数を増加させたときの賃金の影響の方が大きい」ということになります． 逆に，\\({\\beta}_5\\)が負の場合は，その逆のことが起こります．「教育年数が短いほど，経験年数の増加が賃金に与える影響は大きなものになる」と解釈するわけです． これも実際に分析をしてみましょう． lm3 &lt;- lm(formula = salary ~ educ + age + exper + female + educ*exper, data = mydata) summary(lm3) ## ## Call: ## lm(formula = salary ~ educ + age + exper + female + educ * exper, ## data = mydata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -873.97 -188.35 8.26 185.67 1005.39 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -102.0106 96.2473 -1.060 0.2895 ## educ 67.6021 5.9820 11.301 &lt;2e-16 *** ## age 3.6015 1.7479 2.061 0.0396 * ## exper -1.6239 3.4903 -0.465 0.6419 ## female -11.6805 17.2998 -0.675 0.4997 ## educ:exper 0.1379 0.2620 0.526 0.5988 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 272.5 on 994 degrees of freedom ## Multiple R-squared: 0.3365, Adjusted R-squared: 0.3331 ## F-statistic: 100.8 on 5 and 994 DF, p-value: &lt; 2.2e-16 結果はeducは有意に出ますが，experと交差項であるeduc:experは統計的有意性を示しません．これの解釈を行っていきましょう．まず，educは正の影響と推定されているので，教育年数の増加は賃金に正の影響を与えます．experは統計的有意性を示さないので，仕事の経験年数の増加は賃金上昇に影響を与えているわけではないと考えられます．そして，交差項であるeduc:experが有意ではないということは，「教育程度が高いかどうかで，経験年数が賃金に与える影響には差がない」という解釈になります． 5.3 多項式回帰 多項式回帰(Polynomial Regression)とは，次数が2以上の項を含む回帰式です．ここでは2次の項が含まれる回帰式の分析について考えてみます． 今までのモデルに2次の項を入れてみましょう．例えば以下のようなモデル式を考えます． \\[ salary \\ = \\ {\\beta}_0 + {\\beta}_1educ + {\\beta}_2female + {\\beta}_3exper + {\\beta}_3exper^2+ {\\varepsilon} \\] このモデルに含まれる\\(exper^2\\)は2次の項であるので，これは多項式回帰モデルです．この項はどのような意味を持つでしょうか． 経験年数が1年増加することを考えます．そのときの賃金の増加分は微分を行うことによって以下のように計算をできます． \\[ {\\Delta}salary \\ = \\ {\\beta}_3 + 2{\\beta}_4exper \\] もし，この\\({\\beta}_4\\)の係数が統計的に有意であれば，経験年数の増加が賃金に与える影響は経験年数によって異なるということです．例えば，経験年数が5年の人と経験年数が20年の人では，そこからさらに経験年数を積んだ場合に賃金に与える影響は異なることがあるかもしれません．多項式回帰はこのような現象を観察することができるツールです． それでは実際に分析を行ってみましょう． expersq &lt;- mydata$exper^2 lm1 &lt;- lm(formula = salary ~ educ + female + exper + expersq, data = mydata) summary(lm1) ## ## Call: ## lm(formula = salary ~ educ + female + exper + expersq, data = mydata) ## ## Residuals: ## Min 1Q Median 3Q Max ## -887.6 -187.3 8.4 189.8 975.5 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -58.14186 48.94014 -1.188 0.235 ## educ 70.32900 3.15472 22.293 &lt;2e-16 *** ## female -11.61688 17.31254 -0.671 0.502 ## exper 4.36462 2.94606 1.482 0.139 ## expersq -0.10412 0.07105 -1.465 0.143 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 272.6 on 995 degrees of freedom ## Multiple R-squared: 0.3348, Adjusted R-squared: 0.3321 ## F-statistic: 125.2 on 4 and 995 DF, p-value: &lt; 2.2e-16 5.4 対数変換 5.4.1 対数を使うとき 対数変換はその名の通り，変数を対数(log)に変換をして分析を行うことです．一般的に，対数に変化させることでどのようなメリットがあるでしょうか． 5.4.2 対数の解釈 Coming Soon! 5.4.3 対数の変数を用いた分析 Coming Soon! 5.5 パネルデータ 5.5.1 パネルデータとは何か 一般的にデータは，「横断面データ(cross sectional data)」「時系列データ(time series data)」「パネルデータ(panel data)」の3つに分類されます． 横断面データは一時点だけで切り取られたデータを言います．例えば，「2018年における，世界各国のGDP」というデータは，世界各国のGDPを「2018年」という一時点で切り取っています． #data viewing 時系列データはいくつもの時点における数値が観測されているデータのことを指します．例えば，「1998年から2018年までのアメリカ合衆国のGDP」は「アメリカ合衆国のGDP」というデータをいくつもの点で観測して並べることができていますね． #data viewing そして今回扱うパネルデータは，横断面データと時系列データが組み合わさって出来上がっているものと考えると理解しやすいでしょう．すなわち，「1998年から2018年までの世界各国のGDP」というデータはパネルデータです． #data viewing 前節までで扱っていたデータは全て横断面データでした．時系列データの扱いに関してはここでは割愛をしますが，パネルデータの扱いには慣れておくとよいでしょう． 5.5.2 パネルデータを用いるメリット どのような場合にパネルデータを使い，使うことでどんなメリットが得られるようになるでしょうか．それは大きく次の3点にまとめることができます． まず一つ目は，因果推論の条件の一つである『時間的先行』を調べることができるという点です．例えば，「教育への投資が経済成長に与える影響」を調べたいと思うとき，同じ年度の教育投資とGDPの関係を調べても，思うような結果を得ることは難しいでしょう．なぜなら，経済成長をしたために教育への投資を増やしているかもしれませんし（逆の因果関係），仮に教育投資が経済成長を引き起こすとしても，その効果がすぐに現れるとは考えにくいからです．この点をパネルデータを用いて解決することができます．説明変数を従属変数に対して前の時点にとればよいのです．例えば，5年前の教育投資の増加が今の経済成長を引き起こしているとわかれば，時間的先行は担保されていると考えることができます． 二つ目は，データの数を増やすことができるという点です．例えば分析のレベルを国としたとき，運よくすべての国から目的のデータを得ることができたとしても観測数はn=200程度です．これが5つの時点から得ることができればn=1000まで増加します．もちろんこれに対する扱いは気をつけなければならないことがありますが（分析方法は後述します），これは大きなメリットでパネルデータを使うモチベーションの一つです． 三つ目は，分析の対象に固有の効果を打ち消すことができるという点です．例えば，国レベルで分析を行いたいと考えたとき，操作化することができないような，それぞれの国で時間不変の固有の効果を打ち消すことができます．これは横断面データを使った分析よりもパワフルなものになることがあります．これもパネルデータを使うモチベーションのひとつです． では実際に分析の手法を見ていきましょう．それぞれの分析の特性を理解し，使い分けられるようになっていきましょう． 5.5.3 パネルデータ分析：プールドOLS Coming Soon! 5.5.4 パネルデータ分析：固定効果モデル Coming Soon! 5.5.5 パネルデータ分析：ランダム効果モデル Coming Soon! 5.5.6 固定なの？ランダムなの？ Coming Soon! ほとんどの場合，変数の名前に1をとる条件が表れています．例えば，\\(married\\)というダミー変数は，「結婚していれば1，独身であれば0をとる変数」であると解釈します．↩︎ https://freedomhouse.org/↩︎ https://www.systemicpeace.org/polity/polity4.htm↩︎ "],["discrete.html", "チャプター6 離散選択モデル（準備中） 6.1 離れて散り散り？！ 6.2 確率線形モデル 6.3 ロジット回帰 6.4 プロビット回帰 6.5 最尤推定 6.6 順序 6.7 多項", " チャプター6 離散選択モデル（準備中） 準備中 6.1 離れて散り散り？！ 6.2 確率線形モデル 6.3 ロジット回帰 6.4 プロビット回帰 6.5 最尤推定 6.6 順序 6.7 多項 "],["textual.html", "チャプター7 計量テキスト分析（準備中） 7.1 テキストデータとは 7.2 Quantedaは久遠ってんだ？！", " チャプター7 計量テキスト分析（準備中） 準備中 7.1 テキストデータとは 7.2 Quantedaは久遠ってんだ？！ "],["quiz.html", "チャプター8 演習問題", " チャプター8 演習問題 ここまでに学んだ知識を試してみましょう． ここでは架空のデータセットbreakfast.csvを用います． このデータセットには，score，wealth，breakfast，そしてabsent_daysという変数が入っています．ある田舎の市の学校の小学6年生に関するデータです．scoreは，学年末の総合学力テストの成績で100点満点です．wealthはその生徒の家計の主たる稼得者の所得です．breakfastはその生徒が朝食をとる回数の一週間あたりの平均です．absent_daysは年間欠席日数です． あなたは指導教員の先生からリサーチアシスタントを頼まれました．先生から指示された分析を的確にこなし，虎視眈々と共著論文を狙いましょう． 1. メカニズムを考える 教授「うーん，朝食と学力成績ってなんとなく関係がありそうな気がするんだよね．おそらくポジティブな関係があるんちゃうかな．それについての研究をもしかしたらやるかも．ただ，ちょっとボクは忙しいので，君，考えられる因果メカニズムをいくつかまとめといてくれへん？一応，ネガテイブな効果も検討しといて」 2. 記述統計をつくる 教授「すばらしい．仮説はできたやん．次はそれぞれの変数について，平均と標準偏差をまとめておいてくれへん？あと，相関係数もね」 3. 図を描く 教授「やっぱり，数字だけだとわかりづらいねえ．それぞれの変数のヒストラムを作っといてくれる？それから，scoreを縦軸に，それぞれの変数を横軸にして，散布図をつくっといて」 4. 回帰分析をする 教授「さっそく回帰分析をしてみよか．まずは，breakfastで単回帰してから，その後に統制変数を投入してやってみて．結果をきれいにまとめておいて」 5. 結果を解釈する 教授「こんな結果になってしもたんか．ほな，それぞれのモデルについて，解釈を与えておいてください．ほんで，それらを総合して，どういうことが言えそうかまとめといてください」 "],["reference.html", "チャプター9 文献案内", " チャプター9 文献案内 さらに学びを深めたい読者のために，いくつかの文献を紹介します．ちなみに，経済学者の黒川博文先生(Twitter:@kurodotty)がさまざまな因果推論の文献をまとめてくれたありがたいリストを公開しています(因果推論のための計量経済学)．こちらも大いに参考にしてください．Twitterで#因果推論本の読む順番というハッシュタグで検索するといろんな賢い人々が読書の道しるべを示してくれます． 因果推論入門 中室牧子・津川友介（2017）『「原因と結果」の経済学：データから真実を見抜く思考法』ダイヤモンド社． 伊藤公一朗（2017）『データ分析の力：因果関係に迫る思考法』光文社． 中室・津川（2017）も伊藤（2017）も，因果推論の重要性を平易に解説しています．どちらも具体例を交えながら，因果推論の代表的な手法を概説してくれるので，入門書としてぴったりです．とりわけ，中室・津川（2017）は興味深いです．中室・津川（2017）の中で紹介される因果関係の３条件は『原因を推論する』における因果関係の３条件と異なります．その違いについて考えてみることは因果推論の理解を試す良い訓練になります．いずれも数式はほとんど出てきません． 因果推論中級 E.デュフロ・R.グレナスター・M.クレーマー（2019）『政策評価のための因果関係の見つけ方：ランダム化比較試験入門』（小林庸平 監訳）日本評論社． J.アングリスト・J.ピスケ（2013）『「ほとんど無害」な計量経済学―応用経済学のための実証分析ガイド』（大森義明・田中隆一・野口晴子 訳）NTT出版 いずれもより本格的な因果推論の教科書です．数式が出てくるので少ししんどいかもですが，デュフロ他（2019）に関しては，意外と薄いのでなんとかなります．ちなみに，著者の一人であるデュフロは2019年のノーベル経済学賞受賞者です．因果効果を形式的に定義することの便利さを体感してください．アングリスト・ピスケ（2013）もとても有名な教科書です． R入門 浅野正彦・中村公亮（2018）『はじめてのRStudio: エラーメッセージなんかこわくない』オーム社． 邦書の中では，最も読み手に対する優しさを感じさせてくれるRとRStudioの入門書です．ただ，この教科書を読んだ後でも，エラーメッセージはやっぱりこわいです．また，著者であり政治学者である浅野正彦先生(Twitter:@asanoucla)の研究には興味深いものが多いので要チェックです． Rと計量分析 浅野正彦・矢内勇生（2019）『Rによる計量政治学』オーム社． 星野匡郎・田中久稔（2016）『Rによる実証分析：回帰分析から因果分析へ』オーム社 今井耕介（2018）『社会科学のためのデータ分析入門（上）』（粕谷裕子・原田勝孝・久保浩樹 翻訳）岩波書店 今井耕介（2018）『社会科学のためのデータ分析入門（下）』（粕谷裕子・原田勝孝・久保浩樹 翻訳）岩波書店 安井翔太（2020）『効果検証入門〜正しい比較のための因果推論/計量経済学の基礎』（株式会社ホクソエム 監修）技術評論社 浅野・矢内（2019）は非常におすすめです．政治学徒のみならず，経済学徒にも使いやすい教科書です．星野・田中（2016）も定番な感じがあって，おすすめです．今井（2018）は，Rによる計量分析の世界的標準とも言える入門書です．ちなみに今井耕介先生は，一部からは「世界のImai」と呼ばれたりするほどすごい因果推論の研究者です．安井（2020）はTwitterデータサイエンス・計量分析界隈でとても絶賛されていますが，わたしはまだ持っていないのでわかりません．でも，評判を見る限りはかなり良さそうです．おり，わたしも読みましたがとても良かったです．著名な経済学者である大竹文雄先生(Twitter:@fohtake)によると，浅野・矢内（2019）→安井（2020）と読み進めるのが良いらしいです． 経済学部生で計量分析をしてみたい人に最初の一歩としておすすめです。→『Rによる計量政治学』と『効果検証入門』。前者でRに慣れて、後者でRを使った因果推論。 大竹文雄 (@fohtake) January 29, 2020 『維新支持の分析ーポピュリズムか，有権者の合理性か』（有斐閣）の業績によって第41回「サントリー学芸賞」を受賞された善教将大先生(Twitter:@MZenkyo)も，安井（2020）をおすすめしています． 『効果検証入門』は、最近読んだ本の中で、Rでの実践も含め、因果推論入門編の教科書としては一番よかった。https://t.co/jWiMpWGphh — Masahiro Zenkyo (@MZenkyo) January 21, 2020 統計学・計量分析 森棟公夫・照井伸彦・中川満・西埜晴久・黒住英司（2015）『統計学』改訂版，有斐閣 田中隆一（2015）『計量経済学の第一歩 – 実証分析のススメ』有斐閣 西山慶彦・新谷元嗣・川口大司・奥井亮（2019）『計量経済学』有斐閣 森棟他（2015）は基本的な統計学を網羅しており便利です．フルカラーなので親しみやすく，読みやすいです．田中（2015）は読み手に非常に優しい計量経済学の入門書です．正しく「第一歩」に相応しい教科書です．西山他（2019）は計量経済学の代表的な手法を網羅しながら，簡潔で明快な解説がなされており，コンパクトで大変便利な一冊です．計量経済学の世界的標準の入門書としては，WooldridgeのIntroductory Econometricsがありますが，これよりも西山他（2019）の方が優れていると思います．英訳されてもおかしくないくらいの良書です． 大事なこと 計量分析に携わるのであれば，分析手法の力を磨くことはとても大事です．それはスポーツにおける基礎体力に対応するとも言えるでしょう．試合の途中に息切れしてしまっては困ります．とは言え，基礎体力の訓練ばかりしていて，実戦形式の練習を怠ってしまっては元も子もありません．実証家として生きていくならば，これらの本はあくまでも「よくできたクッキング・マニュアル」(『原因を推論する』，p.241)だということを忘れないようにしましょう． "],["postscript.html", "ちょっと短い，少し個人的な，あとがき", " ちょっと短い，少し個人的な，あとがき 本書を読んでくれてありがとうございます．演習論文にあまりリソースを割けなかったので，久米先生にはこちらを代わりに捧げたいと思います． 2019年12月6日 喜久井町のオンボロな民家をのぞむ寝室にて 北川 梨津 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
